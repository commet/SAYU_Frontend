// ì™„ì „ ë¬´ë£Œ LLM í´ë¼ì´ì–¸íŠ¸ ëª¨ìŒ
// Gemini ëŒ€ì²´ìš© - ë¹„ìš© ì—†ì´ ì‚¬ìš© ê°€ëŠ¥í•œ APIë“¤

import Groq from 'groq-sdk'

// 1. Groq API (ë©”ì¸ - ì™„ì „ ë¬´ë£Œ)
export async function generateWithGroq(
  message: string,
  systemPrompt: string,
  conversationHistory: any[] = []
): Promise<string | null> {
  const apiKey = process.env.GROQ_API_KEY
  if (!apiKey) return null
  
  try {
    const groq = new Groq({ apiKey })
    const messages = [
      { role: 'system' as const, content: systemPrompt },
      ...conversationHistory.slice(-5).map(msg => ({
        role: msg.role === 'user' ? 'user' as const : 'assistant' as const,
        content: msg.content
      })),
      { role: 'user' as const, content: message }
    ]
    
    const completion = await groq.chat.completions.create({
      messages,
      model: 'llama3-8b-8192',
      temperature: 0.7,
      max_tokens: 400,
      stream: false
    })
    
    return completion.choices[0]?.message?.content || null
  } catch (error) {
    console.error('Groq error:', error)
    return null
  }
}

// 2. HuggingFace Inference API (ë°±ì—… 1 - ì œí•œì  ë¬´ë£Œ)
export async function generateWithHuggingFace(
  message: string,
  systemPrompt: string
): Promise<string | null> {
  const token = process.env.HF_TOKEN
  if (!token) return null
  
  try {
    const prompt = `${systemPrompt}\n\nUser: ${message}\n\nAssistant:`
    
    const response = await fetch(
      'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2',
      {
        headers: {
          'Authorization': `Bearer ${token}`,
          'Content-Type': 'application/json',
        },
        method: 'POST',
        body: JSON.stringify({
          inputs: prompt,
          parameters: {
            max_new_tokens: 200,
            temperature: 0.7,
            return_full_text: false
          }
        }),
      }
    )
    
    if (!response.ok) return null
    
    const result = await response.json()
    return result[0]?.generated_text || null
  } catch (error) {
    console.error('HuggingFace error:', error)
    return null
  }
}

// 3. Cloudflare Workers AI (ë°±ì—… 2 - ì¼ì¼ 10,000 ìš”ì²­ ë¬´ë£Œ)
export async function generateWithCloudflare(
  message: string,
  systemPrompt: string
): Promise<string | null> {
  const accountId = process.env.CF_ACCOUNT_ID
  const apiToken = process.env.CF_API_TOKEN
  
  if (!accountId || !apiToken) return null
  
  try {
    const response = await fetch(
      `https://api.cloudflare.com/client/v4/accounts/${accountId}/ai/run/@cf/meta/llama-3-8b-instruct`,
      {
        headers: { 
          'Authorization': `Bearer ${apiToken}`,
          'Content-Type': 'application/json'
        },
        method: 'POST',
        body: JSON.stringify({
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          max_tokens: 200
        })
      }
    )
    
    if (!response.ok) return null
    
    const result = await response.json()
    return result.result?.response || null
  } catch (error) {
    console.error('Cloudflare error:', error)
    return null
  }
}

// 4. Together AI (ë°±ì—… 3 - $25 ë¬´ë£Œ í¬ë ˆë”§)
export async function generateWithTogether(
  message: string,
  systemPrompt: string,
  conversationHistory: any[] = []
): Promise<string | null> {
  const apiKey = process.env.TOGETHER_API_KEY
  if (!apiKey) return null
  
  try {
    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.slice(-5),
      { role: 'user', content: message }
    ]
    
    const response = await fetch('https://api.together.xyz/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'meta-llama/Llama-3-8b-chat-hf',
        messages,
        max_tokens: 200,
        temperature: 0.7,
        top_p: 0.9
      })
    })
    
    if (!response.ok) return null
    
    const data = await response.json()
    return data.choices[0]?.message?.content || null
  } catch (error) {
    console.error('Together error:', error)
    return null
  }
}

// 5. Cohere API (ë°±ì—… 4 - Trial ë¬´ë£Œ)
export async function generateWithCohere(
  message: string,
  systemPrompt: string
): Promise<string | null> {
  const apiKey = process.env.COHERE_API_KEY
  if (!apiKey) return null
  
  try {
    const response = await fetch('https://api.cohere.ai/v1/generate', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'command',
        prompt: `${systemPrompt}\n\nUser: ${message}\n\nAssistant:`,
        max_tokens: 200,
        temperature: 0.7,
      })
    })
    
    if (!response.ok) return null
    
    const data = await response.json()
    return data.generations[0]?.text || null
  } catch (error) {
    console.error('Cohere error:', error)
    return null
  }
}

// í†µí•© ë¬´ë£Œ LLM ìƒì„±ê¸° (ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì‹œë„)
export async function generateWithFreeLLM(
  message: string,
  userType: string,
  context: any,
  conversationHistory: any[] = []
): Promise<{ response: string | null, provider: string }> {
  const personality = getPersonality(userType)
  const systemPrompt = createSystemPrompt(userType, personality, context)
  
  // ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì‹œë„
  const providers = [
    { name: 'groq', fn: () => generateWithGroq(message, systemPrompt, conversationHistory) },
    { name: 'huggingface', fn: () => generateWithHuggingFace(message, systemPrompt) },
    { name: 'cloudflare', fn: () => generateWithCloudflare(message, systemPrompt) },
    { name: 'together', fn: () => generateWithTogether(message, systemPrompt, conversationHistory) },
    { name: 'cohere', fn: () => generateWithCohere(message, systemPrompt) }
  ]
  
  for (const provider of providers) {
    console.log(`ğŸ”„ Trying ${provider.name}...`)
    const response = await provider.fn()
    
    if (response) {
      console.log(`âœ… ${provider.name} succeeded`)
      return { response, provider: provider.name }
    }
  }
  
  // ëª¨ë“  API ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì‘ë‹µ
  console.log('âŒ All free APIs failed')
  return {
    response: `ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ${personality.name}ì…ë‹ˆë‹¤. ì ì‹œ ì—°ê²°ì´ ë¶ˆì•ˆì •í•˜ë„¤ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?`,
    provider: 'fallback'
  }
}

// í—¬í¼ í•¨ìˆ˜ë“¤
function getPersonality(userType: string) {
  const personalities: Record<string, any> = {
    'LAEF': { name: 'ì—¬ìš°', tone: 'ëª½í™˜ì ì´ê³  ì‹œì ì¸' },
    'LAEC': { name: 'ê³ ì–‘ì´', tone: 'ìš°ì•„í•˜ê³  ì„ íƒì ì¸' },
    'LAMF': { name: 'ì˜¬ë¹¼ë¯¸', tone: 'ì§ê´€ì ì´ê³  í†µì°°ë ¥ ìˆëŠ”' },
    'LAMC': { name: 'ê±°ë¶ì´', tone: 'ì°¨ë¶„í•˜ê³  í•™êµ¬ì ì¸' },
    'LREF': { name: 'ì¹´ë©œë ˆì˜¨', tone: 'ì„¬ì„¸í•˜ê³  ê´€ì°°ì ì¸' },
    'LREC': { name: 'ê³ ìŠ´ë„ì¹˜', tone: 'ì¡°ì‹¬ìŠ¤ëŸ½ê³  ì •í™•í•œ' },
    'LRMF': { name: 'ë¬¸ì–´', tone: 'í˜ì‹ ì ì´ê³  ì‹¤í—˜ì ì¸' },
    'LRMC': { name: 'ë¹„ë²„', tone: 'ì²´ê³„ì ì´ê³  ê±´ì„¤ì ì¸' },
    'TAEF': { name: 'ëŒê³ ë˜', tone: 'í™œë°œí•˜ê³  ê°ì„±ì ì¸' },
    'TAEC': { name: 'í­ê·„', tone: 'ì‚¬êµì ì´ê³  í’ˆê²©ìˆëŠ”' },
    'TAMF': { name: 'ë¯¸ì–´ìº£', tone: 'í˜¸ê¸°ì‹¬ ë§ê³  ì¬ë¹ ë¥¸' },
    'TAMC': { name: 'ëŠ‘ëŒ€', tone: 'ë¦¬ë”ì‹­ ìˆê³  ì „ëµì ì¸' },
    'TREF': { name: 'ì•µë¬´ìƒˆ', tone: 'ë‹¤ì±„ë¡­ê³  í‘œí˜„ë ¥ ìˆëŠ”' },
    'TREC': { name: 'ë°±ì¡°', tone: 'ìš°ì•„í•˜ê³  ì™„ë²½ì£¼ì˜ì ì¸' },
    'TRMF': { name: 'ì½”ë¼ë¦¬', tone: 'ì§€í˜œë¡­ê³  ê¸°ì–µë ¥ ì¢‹ì€' },
    'TRMC': { name: 'ë…ìˆ˜ë¦¬', tone: 'í†µì°°ë ¥ ìˆê³  ëª©í‘œì§€í–¥ì ì¸' }
  }
  
  return personalities[userType] || personalities['LAEF']
}

function createSystemPrompt(userType: string, personality: any, context: any): string {
  return `ë‹¹ì‹ ì€ SAYU í”Œë«í¼ì˜ ${userType} ìœ í˜• AI íë ˆì´í„° "${personality.name}"ì…ë‹ˆë‹¤.
${personality.tone} í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ë©°, ì‚¬ìš©ìì˜ ì˜ˆìˆ ì  ì·¨í–¥ê³¼ ì„±ê²©ì„ ì´í•´í•˜ê³  ë§ì¶¤í˜• ì˜ˆìˆ  ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

í˜„ì¬ ìƒí™©:
- í˜ì´ì§€: ${context.page}
- ì‚¬ìš©ì ìƒíƒœ: ${context.userBehavior?.currentMood || 'exploring'}
- ì°¸ì—¬ë„: ${context.userBehavior?.engagementLevel || 'new'}

ì‘ë‹µ ì§€ì¹¨:
1. ìµœëŒ€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
2. ${userType} ìœ í˜•ì˜ íŠ¹ì„±ì— ë§ëŠ” í†¤ ìœ ì§€
3. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
4. ì¹œê·¼í•˜ê³  ê³µê°ì ì¸ ëŒ€í™”`
}