#!/usr/bin/env node

/**
 * Railway Cron Job Service
 * ìžë™í™”ëœ ì „ì‹œ ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬ ìž‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
 */

const cron = require('node-cron');
require('dotenv').config();

// Services
const SupabaseExhibitionCollector = require('./src/services/supabaseExhibitionCollector');
const DatabaseBackup = require('./src/utils/databaseBackup');
const { log } = require('./src/config/logger');

class RailwayCronService {
  constructor() {
    this.jobs = new Map();
    this.isProduction = process.env.NODE_ENV === 'production';
    this.enabledJobs = this.getEnabledJobs();
  }

  getEnabledJobs() {
    // í™˜ê²½ë³€ìˆ˜ë¡œ í™œì„±í™”í•  ìž‘ì—… ì œì–´
    const enabled = (process.env.ENABLED_CRON_JOBS || 'all').split(',');
    return enabled.includes('all') ? [
      'exhibition-collection',
      'data-backup',
      'system-maintenance',
      'status-update'
    ] : enabled;
  }

  // ì „ì‹œ ë°ì´í„° ìˆ˜ì§‘ (ë§¤ì¼ ì˜¤ì „ 6ì‹œ)
  scheduleExhibitionCollection() {
    if (!this.enabledJobs.includes('exhibition-collection')) return;

    const job = cron.schedule('0 6 * * *', async () => {
      log.info('ðŸŽ¨ Starting automated exhibition collection...');

      try {
        const collector = new SupabaseExhibitionCollector();

        // Naver APIì—ì„œ ì „ì‹œ ë°ì´í„° ìˆ˜ì§‘
        const results = await collector.collectExhibitionsFromNaver({
          maxResults: 50, // í•˜ë£¨ ìµœëŒ€ 50ê°œ
          region: 'all',
          category: 'exhibition'
        });

        log.info('Exhibition collection completed', {
          collected: results.collected,
          duplicates: results.duplicates,
          errors: results.errors,
          timestamp: new Date().toISOString()
        });

        // ì„±ê³µ ë©”íŠ¸ë¦­ ê¸°ë¡
        await this.recordJobMetric('exhibition-collection', 'success', {
          collected: results.collected,
          duplicates: results.duplicates
        });

      } catch (error) {
        log.error('Exhibition collection failed', {
          error: error.message,
          stack: error.stack,
          timestamp: new Date().toISOString()
        });

        // ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ê¸°ë¡
        await this.recordJobMetric('exhibition-collection', 'failed', {
          error: error.message
        });
      }
    }, {
      scheduled: false,
      timezone: 'Asia/Seoul'
    });

    this.jobs.set('exhibition-collection', job);
    log.info('ðŸ“… Exhibition collection job scheduled (daily 6:00 AM KST)');
  }

  // ë°ì´í„° ë°±ì—… (ë§¤ì¼ ì˜¤ì „ 2ì‹œ)
  scheduleDataBackup() {
    if (!this.enabledJobs.includes('data-backup')) return;

    const job = cron.schedule('0 2 * * *', async () => {
      log.info('ðŸ’¾ Starting automated data backup...');

      try {
        const backup = new DatabaseBackup();

        // ì „ì‹œ ë°ì´í„° ë°±ì—…
        const result = await backup.backupExhibitionData();

        // ì˜¤ëž˜ëœ ë°±ì—… ì •ë¦¬ (30ì¼ ì´ìƒ)
        const cleaned = await backup.cleanupOldBackups(30);

        log.info('Data backup completed', {
          backupFile: result.filename,
          cleanedBackups: cleaned.deletedCount,
          timestamp: new Date().toISOString()
        });

        await this.recordJobMetric('data-backup', 'success', {
          backupFile: result.filename,
          cleanedCount: cleaned.deletedCount
        });

      } catch (error) {
        log.error('Data backup failed', {
          error: error.message,
          stack: error.stack,
          timestamp: new Date().toISOString()
        });

        await this.recordJobMetric('data-backup', 'failed', {
          error: error.message
        });
      }
    }, {
      scheduled: false,
      timezone: 'Asia/Seoul'
    });

    this.jobs.set('data-backup', job);
    log.info('ðŸ“… Data backup job scheduled (daily 2:00 AM KST)');
  }

  // ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ (ë§¤ì£¼ ì¼ìš”ì¼ ì˜¤ì „ 3ì‹œ)
  scheduleSystemMaintenance() {
    if (!this.enabledJobs.includes('system-maintenance')) return;

    const job = cron.schedule('0 3 * * 0', async () => {
      log.info('ðŸ”§ Starting system maintenance...');

      try {
        const tasks = [];

        // 1. ë§Œë£Œëœ ì „ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
        tasks.push(this.updateExpiredExhibitions());

        // 2. ì˜¤ëž˜ëœ ë¡œê·¸ ì •ë¦¬
        tasks.push(this.cleanupOldLogs());

        // 3. ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì—…ë°ì´íŠ¸
        tasks.push(this.updateDatabaseStats());

        // 4. ìºì‹œ ì •ë¦¬
        tasks.push(this.clearExpiredCache());

        const results = await Promise.allSettled(tasks);

        const summary = {
          total: results.length,
          success: results.filter(r => r.status === 'fulfilled').length,
          failed: results.filter(r => r.status === 'rejected').length
        };

        log.info('System maintenance completed', {
          summary,
          timestamp: new Date().toISOString()
        });

        await this.recordJobMetric('system-maintenance', 'success', summary);

      } catch (error) {
        log.error('System maintenance failed', {
          error: error.message,
          stack: error.stack,
          timestamp: new Date().toISOString()
        });

        await this.recordJobMetric('system-maintenance', 'failed', {
          error: error.message
        });
      }
    }, {
      scheduled: false,
      timezone: 'Asia/Seoul'
    });

    this.jobs.set('system-maintenance', job);
    log.info('ðŸ“… System maintenance job scheduled (weekly Sunday 3:00 AM KST)');
  }

  // ì „ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸ (ë§¤ì¼ ì˜¤ì „ 9ì‹œ)
  scheduleStatusUpdate() {
    if (!this.enabledJobs.includes('status-update')) return;

    const job = cron.schedule('0 9 * * *', async () => {
      log.info('ðŸ“Š Starting exhibition status update...');

      try {
        const { createClient } = require('@supabase/supabase-js');
        const supabase = createClient(
          process.env.SUPABASE_URL,
          process.env.SUPABASE_SERVICE_KEY
        );

        const today = new Date().toISOString().split('T')[0];

        // ì§„í–‰ ì¤‘ìœ¼ë¡œ ë³€ê²½ (ì‹œìž‘ì¼ì´ ì˜¤ëŠ˜ ì´ì „ì´ê³  ì¢…ë£Œì¼ì´ ì˜¤ëŠ˜ ì´í›„)
        const { data: ongoing, error: ongoingError } = await supabase
          .from('exhibitions')
          .update({ status: 'ongoing', updated_at: new Date().toISOString() })
          .lte('start_date', today)
          .gte('end_date', today)
          .eq('status', 'upcoming')
          .select('id');

        // ì¢…ë£Œë¡œ ë³€ê²½ (ì¢…ë£Œì¼ì´ ì˜¤ëŠ˜ ì´ì „)
        const { data: ended, error: endedError } = await supabase
          .from('exhibitions')
          .update({ status: 'ended', updated_at: new Date().toISOString() })
          .lt('end_date', today)
          .in('status', ['upcoming', 'ongoing'])
          .select('id');

        if (ongoingError || endedError) {
          throw new Error(`Status update error: ${ongoingError?.message || endedError?.message}`);
        }

        const summary = {
          ongoing: ongoing?.length || 0,
          ended: ended?.length || 0,
          total: (ongoing?.length || 0) + (ended?.length || 0)
        };

        log.info('Exhibition status update completed', {
          summary,
          timestamp: new Date().toISOString()
        });

        await this.recordJobMetric('status-update', 'success', summary);

      } catch (error) {
        log.error('Exhibition status update failed', {
          error: error.message,
          stack: error.stack,
          timestamp: new Date().toISOString()
        });

        await this.recordJobMetric('status-update', 'failed', {
          error: error.message
        });
      }
    }, {
      scheduled: false,
      timezone: 'Asia/Seoul'
    });

    this.jobs.set('status-update', job);
    log.info('ðŸ“… Exhibition status update job scheduled (daily 9:00 AM KST)');
  }

  // ë§Œë£Œëœ ì „ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
  async updateExpiredExhibitions() {
    const { createClient } = require('@supabase/supabase-js');
    const supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_SERVICE_KEY
    );

    const today = new Date().toISOString().split('T')[0];

    const { data, error } = await supabase
      .from('exhibitions')
      .update({
        status: 'ended',
        updated_at: new Date().toISOString()
      })
      .lt('end_date', today)
      .neq('status', 'ended')
      .select('id');

    if (error) throw error;

    log.info(`Updated ${data?.length || 0} expired exhibitions to 'ended' status`);
    return data?.length || 0;
  }

  // ì˜¤ëž˜ëœ ë¡œê·¸ ì •ë¦¬
  async cleanupOldLogs() {
    // ë¡œê·¸ ì •ë¦¬ ë¡œì§ (í•„ìš”ì‹œ êµ¬í˜„)
    log.info('Log cleanup completed');
    return true;
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì—…ë°ì´íŠ¸
  async updateDatabaseStats() {
    const { createClient } = require('@supabase/supabase-js');
    const supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_SERVICE_KEY
    );

    // ì „ì‹œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
    const { count: exhibitionCount } = await supabase
      .from('exhibitions')
      .select('*', { count: 'exact', head: true });

    // ì œì¶œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
    const { count: submissionCount } = await supabase
      .from('exhibition_submissions')
      .select('*', { count: 'exact', head: true });

    log.info('Database stats updated', {
      exhibitions: exhibitionCount,
      submissions: submissionCount
    });

    return { exhibitions: exhibitionCount, submissions: submissionCount };
  }

  // ìºì‹œ ì •ë¦¬
  async clearExpiredCache() {
    try {
      const { redisClient } = require('./src/config/redis');
      if (redisClient) {
        // Redis ìºì‹œ ì •ë¦¬ ë¡œì§
        log.info('Cache cleanup completed');
      }
    } catch (error) {
      log.warn('Cache cleanup skipped (Redis not available)');
    }
    return true;
  }

  // ìž‘ì—… ë©”íŠ¸ë¦­ ê¸°ë¡
  async recordJobMetric(jobName, status, metadata = {}) {
    try {
      const { createClient } = require('@supabase/supabase-js');
      const supabase = createClient(
        process.env.SUPABASE_URL,
        process.env.SUPABASE_SERVICE_KEY
      );

      await supabase
        .from('cron_job_logs')
        .insert({
          job_name: jobName,
          status,
          metadata,
          executed_at: new Date().toISOString(),
          execution_time: Date.now() // ì‹¤í–‰ ì‹œê°„ ê¸°ë¡ìš©
        });

    } catch (error) {
      log.warn('Failed to record job metric', { error: error.message });
    }
  }

  // ëª¨ë“  ìž‘ì—… ì‹œìž‘
  startAllJobs() {
    log.info('ðŸš€ Starting Railway Cron Service...');
    log.info(`Environment: ${this.isProduction ? 'Production' : 'Development'}`);
    log.info(`Enabled jobs: ${this.enabledJobs.join(', ')}`);

    // ëª¨ë“  ìž‘ì—… ìŠ¤ì¼€ì¤„ë§
    this.scheduleExhibitionCollection();
    this.scheduleDataBackup();
    this.scheduleSystemMaintenance();
    this.scheduleStatusUpdate();

    // ìž‘ì—… ì‹œìž‘
    this.jobs.forEach((job, name) => {
      job.start();
      log.info(`âœ… Started job: ${name}`);
    });

    log.info(`ðŸŽ¯ ${this.jobs.size} cron jobs are now running`);

    // í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (Railwayì—ì„œ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ìš©)
    this.startHealthServer();
  }

  // í—¬ìŠ¤ì²´í¬ ì„œë²„ ì‹œìž‘
  startHealthServer() {
    const express = require('express');
    const app = express();
    const port = process.env.PORT || 8080;

    app.get('/health', (req, res) => {
      const jobStatuses = {};
      this.jobs.forEach((job, name) => {
        jobStatuses[name] = {
          running: job.running,
          scheduled: job.scheduled
        };
      });

      res.json({
        status: 'healthy',
        timestamp: new Date().toISOString(),
        jobs: jobStatuses,
        environment: process.env.NODE_ENV,
        enabledJobs: this.enabledJobs
      });
    });

    app.get('/jobs/trigger/:jobName', async (req, res) => {
      const { jobName } = req.params;

      if (!this.jobs.has(jobName)) {
        return res.status(404).json({ error: 'Job not found' });
      }

      try {
        // ìˆ˜ë™ìœ¼ë¡œ ìž‘ì—… ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
        log.info(`Manual trigger requested for job: ${jobName}`);

        // ìž‘ì—…ë³„ ìˆ˜ë™ ì‹¤í–‰ ë¡œì§
        if (jobName === 'exhibition-collection') {
          const collector = new SupabaseExhibitionCollector();
          const results = await collector.collectExhibitionsFromNaver({ maxResults: 10 });
          res.json({ success: true, results });
        } else if (jobName === 'data-backup') {
          const backup = new DatabaseBackup();
          const result = await backup.backupExhibitionData();
          res.json({ success: true, result });
        } else {
          res.json({ success: true, message: `Job ${jobName} triggered` });
        }

      } catch (error) {
        log.error(`Manual job trigger failed: ${jobName}`, { error: error.message });
        res.status(500).json({ error: error.message });
      }
    });

    app.listen(port, () => {
      log.info(`ðŸ¥ Health server running on port ${port}`);
    });
  }

  // ëª¨ë“  ìž‘ì—… ì¤‘ì§€
  stopAllJobs() {
    log.info('ðŸ›‘ Stopping all cron jobs...');

    this.jobs.forEach((job, name) => {
      job.stop();
      log.info(`âŒ Stopped job: ${name}`);
    });

    log.info('All cron jobs stopped');
  }
}

// Railwayì—ì„œ ì‹¤í–‰ë  ë•Œ
if (require.main === module) {
  const cronService = new RailwayCronService();

  // Graceful shutdown
  process.on('SIGTERM', () => {
    log.info('ðŸ Received SIGTERM, shutting down gracefully...');
    cronService.stopAllJobs();
    process.exit(0);
  });

  process.on('SIGINT', () => {
    log.info('ðŸ Received SIGINT, shutting down gracefully...');
    cronService.stopAllJobs();
    process.exit(0);
  });

  // ì—ëŸ¬ í•¸ë“¤ë§
  process.on('uncaughtException', (error) => {
    log.error('Uncaught exception in cron service', {
      error: error.message,
      stack: error.stack
    });
    process.exit(1);
  });

  process.on('unhandledRejection', (reason, promise) => {
    log.error('Unhandled rejection in cron service', {
      reason: reason.toString(),
      promise: promise.toString()
    });
  });

  // ì„œë¹„ìŠ¤ ì‹œìž‘
  cronService.startAllJobs();
}

module.exports = RailwayCronService;
