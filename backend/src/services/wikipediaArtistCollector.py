#!/usr/bin/env python3
"""
SAYU Wikipedia ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘ê¸°
Python Wikipedia-APIë¥¼ í™œìš©í•œ ì •ë°€í•œ ì•„í‹°ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘

ì„¤ì¹˜ ë°©ë²•:
pip install wikipedia-api requests psycopg2-binary openai

ì‚¬ìš©ë²•:
python wikipediaArtistCollector.py --artist "Pablo Picasso"
python wikipediaArtistCollector.py --batch artists_list.txt
"""

import wikipediaapi
import requests
import json
import re
import sys
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
import psycopg2
from psycopg2.extras import RealDictCursor
import openai
import os
from dataclasses import dataclass

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('artist_collection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class ArtistInfo:
    """ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    name_ko: Optional[str] = None
    birth_year: Optional[int] = None
    death_year: Optional[int] = None
    birth_date: Optional[str] = None
    death_date: Optional[str] = None
    nationality: Optional[str] = None
    nationality_ko: Optional[str] = None
    biography: Optional[str] = None
    biography_ko: Optional[str] = None
    art_movement: Optional[str] = None
    birth_place: Optional[str] = None
    death_place: Optional[str] = None
    education: Optional[List[str]] = None
    notable_works: Optional[List[str]] = None
    awards: Optional[List[str]] = None
    influences: Optional[List[str]] = None
    influenced: Optional[List[str]] = None
    spouse: Optional[str] = None
    image_url: Optional[str] = None
    wikipedia_url: Optional[str] = None
    wikidata_id: Optional[str] = None
    categories: Optional[List[str]] = None
    references: Optional[List[str]] = None
    
class WikipediaArtistCollector:
    """Wikipedia APIë¥¼ í™œìš©í•œ ì •ë°€ ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        # Wikipedia API ì„¤ì • (ë‹¤êµ­ì–´ ì§€ì›)
        self.wiki_en = wikipediaapi.Wikipedia(
            language='en',
            extract_format=wikipediaapi.ExtractFormat.WIKI,
            user_agent='SAYU-ArtCollector/1.0 (https://sayu.life) Data Collection Bot'
        )
        
        self.wiki_ko = wikipediaapi.Wikipedia(
            language='ko',
            extract_format=wikipediaapi.ExtractFormat.WIKI,
            user_agent='SAYU-ArtCollector/1.0 (https://sayu.life) Data Collection Bot'
        )
        
        # OpenAI ì„¤ì •
        if os.getenv('OPENAI_API_KEY'):
            openai.api_key = os.getenv('OPENAI_API_KEY')
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': os.getenv('DB_PORT', 5432),
            'database': os.getenv('DB_NAME', 'sayu'),
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', '')
        }
        
        # ì˜ˆìˆ  ê´€ë ¨ í‚¤ì›Œë“œ (ì •í™•ë„ í–¥ìƒìš©)
        self.art_keywords = [
            'painter', 'artist', 'sculptor', 'photographer', 'printmaker',
            'conceptual artist', 'installation artist', 'performance artist',
            'ceramic artist', 'textile artist', 'video artist', 'digital artist'
        ]
        
        # ì˜ˆìˆ  ì‚¬ì¡° ë§¤í•‘
        self.art_movements = {
            'impressionism': 'ì¸ìƒì£¼ì˜',
            'expressionism': 'í‘œí˜„ì£¼ì˜', 
            'cubism': 'ì…ì²´ì£¼ì˜',
            'surrealism': 'ì´ˆí˜„ì‹¤ì£¼ì˜',
            'abstract expressionism': 'ì¶”ìƒí‘œí˜„ì£¼ì˜',
            'pop art': 'íŒì•„íŠ¸',
            'minimalism': 'ë¯¸ë‹ˆë©€ë¦¬ì¦˜',
            'conceptual art': 'ê°œë…ë¯¸ìˆ ',
            'dadaism': 'ë‹¤ë‹¤ì´ì¦˜',
            'fauvism': 'ì•¼ìˆ˜ì£¼ì˜',
            'futurism': 'ë¯¸ë˜ì£¼ì˜',
            'constructivism': 'êµ¬ì„±ì£¼ì˜'
        }

    def search_artist(self, artist_name: str) -> Optional[ArtistInfo]:
        """
        ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ìœ¼ë¡œ Wikipedia ê²€ìƒ‰ ë° ì •ë³´ ìˆ˜ì§‘
        """
        logger.info(f"ğŸ¨ Wikipediaì—ì„œ '{artist_name}' ê²€ìƒ‰ ì‹œì‘")
        
        try:
            # 1. ì˜ë¬¸ Wikipedia ê²€ìƒ‰
            en_page = self.wiki_en.page(artist_name)
            
            if not en_page.exists():
                # ê²€ìƒ‰ì–´ ë³€í˜• ì‹œë„
                search_results = self.search_variations(artist_name)
                if search_results:
                    en_page = self.wiki_en.page(search_results[0])
                else:
                    logger.warning(f"ì˜ë¬¸ Wikipediaì—ì„œ '{artist_name}' ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return None
            
            # ì•„í‹°ìŠ¤íŠ¸ ì—¬ë¶€ í™•ì¸
            if not self.is_artist_page(en_page):
                logger.warning(f"'{artist_name}'ì€(ëŠ”) ì•„í‹°ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²ƒìœ¼ë¡œ íŒë‹¨ë¨")
                return None
            
            # 2. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            artist_info = self.extract_basic_info(en_page)
            
            # 3. í•œêµ­ì–´ Wikipedia ê²€ìƒ‰
            ko_info = self.search_korean_wikipedia(artist_name, artist_info)
            if ko_info:
                artist_info = self.merge_korean_info(artist_info, ko_info)
            
            # 4. Wikidata ì •ë³´ ì¶”ê°€
            wikidata_info = self.fetch_wikidata_info(artist_info.wikidata_id)
            if wikidata_info:
                artist_info = self.merge_wikidata_info(artist_info, wikidata_info)
            
            # 5. ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘
            artist_info.image_url = self.extract_main_image(en_page)
            
            # 6. ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ
            artist_info.categories = self.extract_categories(en_page)
            
            # 7. ì°¸ê³  ë¬¸í—Œ ì¶”ì¶œ
            artist_info.references = self.extract_references(en_page)
            
            logger.info(f"âœ… '{artist_name}' ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            return artist_info
            
        except Exception as e:
            logger.error(f"âŒ '{artist_name}' ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def is_artist_page(self, page) -> bool:
        """
        í˜ì´ì§€ê°€ ì•„í‹°ìŠ¤íŠ¸ ê´€ë ¨ì¸ì§€ í™•ì¸
        """
        content = page.text.lower()
        categories = [cat.lower() for cat in page.categories.keys()]
        
        # ì•„í‹°ìŠ¤íŠ¸ í‚¤ì›Œë“œ í™•ì¸
        for keyword in self.art_keywords:
            if keyword in content[:1000]:  # ì²« 1000ìì—ì„œ í™•ì¸
                return True
        
        # ì¹´í…Œê³ ë¦¬ì—ì„œ í™•ì¸
        artist_categories = [
            'artists', 'painters', 'sculptors', 'photographers',
            'american artists', 'french artists', 'british artists',
            'contemporary artists', 'modern artists'
        ]
        
        for cat in categories:
            for art_cat in artist_categories:
                if art_cat in cat:
                    return True
        
        return False
    
    def extract_basic_info(self, page) -> ArtistInfo:
        """
        Wikipedia í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        """
        content = page.text
        
        artist_info = ArtistInfo(
            name=page.title,
            wikipedia_url=page.fullurl,
            biography=content[:2000] if len(content) > 2000 else content  # ì²˜ìŒ 2000ì
        )
        
        # ìƒëª°ë…„ë„ ì¶”ì¶œ
        birth_death = self.extract_birth_death_dates(content)
        artist_info.birth_year = birth_death.get('birth_year')
        artist_info.death_year = birth_death.get('death_year')
        artist_info.birth_date = birth_death.get('birth_date')
        artist_info.death_date = birth_death.get('death_date')
        
        # êµ­ì  ì¶”ì¶œ
        artist_info.nationality = self.extract_nationality(content)
        
        # ì¶œìƒì§€ ì¶”ì¶œ
        artist_info.birth_place = self.extract_birth_place(content)
        
        # ì˜ˆìˆ  ì‚¬ì¡° ì¶”ì¶œ
        artist_info.art_movement = self.extract_art_movement(content)
        
        # ì£¼ìš” ì‘í’ˆ ì¶”ì¶œ
        artist_info.notable_works = self.extract_notable_works(content)
        
        # Wikidata ID ì¶”ì¶œ
        artist_info.wikidata_id = self.extract_wikidata_id(page)
        
        return artist_info
    
    def extract_birth_death_dates(self, content: str) -> Dict[str, Any]:
        """
        ìƒëª°ë…„ë„ ì •ë°€ ì¶”ì¶œ
        """
        result = {}
        
        # ë‹¤ì–‘í•œ ë‚ ì§œ íŒ¨í„´
        patterns = [
            # (1881-1973)
            r'\((\d{4})[â€“-](\d{4})\)',
            # born 1881, died 1973
            r'born\s+(\d{4}).*?died\s+(\d{4})',
            # 1881â€“1973
            r'(\d{4})[â€“-](\d{4})',
            # born on 25 October 1881
            r'born\s+(?:on\s+)?(\d{1,2}\s+\w+\s+\d{4})',
            # died 8 April 1973
            r'died\s+(\d{1,2}\s+\w+\s+\d{4})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                if len(match.groups()) == 2 and match.group(1).isdigit() and match.group(2).isdigit():
                    result['birth_year'] = int(match.group(1))
                    result['death_year'] = int(match.group(2))
                    break
        
        # ê°œë³„ ë‚ ì§œ íŒ¨í„´
        birth_match = re.search(r'born\s+(?:on\s+)?([^,\n]+)', content[:1000], re.IGNORECASE)
        if birth_match:
            result['birth_date'] = birth_match.group(1).strip()
            
        death_match = re.search(r'died\s+([^,\n]+)', content[:1000], re.IGNORECASE)
        if death_match:
            result['death_date'] = death_match.group(1).strip()
        
        return result
    
    def extract_nationality(self, content: str) -> Optional[str]:
        """
        êµ­ì  ì¶”ì¶œ
        """
        patterns = [
            r'(\w+)\s+(?:painter|artist|sculptor|photographer)',
            r'was\s+a\s+(\w+)',
            r'born\s+in\s+([^,\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content[:500], re.IGNORECASE)
            if match:
                nationality = match.group(1).strip()
                # ìœ ëª…í•œ êµ­ì ë“¤ í™•ì¸
                known_nationalities = [
                    'American', 'French', 'Spanish', 'Italian', 'German', 
                    'British', 'Dutch', 'Russian', 'Japanese', 'Korean',
                    'Chinese', 'Mexican', 'Brazilian', 'Indian'
                ]
                if nationality in known_nationalities:
                    return nationality
        
        return None
    
    def extract_birth_place(self, content: str) -> Optional[str]:
        """
        ì¶œìƒì§€ ì¶”ì¶œ
        """
        pattern = r'born\s+(?:in\s+)?([^,\n\(]+)'
        match = re.search(pattern, content[:1000], re.IGNORECASE)
        if match:
            return match.group(1).strip()
        return None
    
    def extract_art_movement(self, content: str) -> Optional[str]:
        """
        ì˜ˆìˆ  ì‚¬ì¡° ì¶”ì¶œ
        """
        content_lower = content.lower()
        
        for movement, korean in self.art_movements.items():
            if movement in content_lower:
                return movement.title()
        
        return None
    
    def extract_notable_works(self, content: str) -> List[str]:
        """
        ì£¼ìš” ì‘í’ˆ ì¶”ì¶œ
        """
        works = []
        
        # "Notable works" ì„¹ì…˜ ì°¾ê¸°
        notable_section = re.search(
            r'(?:notable works?|major works?|famous works?)[:\n](.*?)(?:\n\n|\n[A-Z])', 
            content, 
            re.IGNORECASE | re.DOTALL
        )
        
        if notable_section:
            section_text = notable_section.group(1)
            # ì‘í’ˆëª… íŒ¨í„´ (ë”°ì˜´í‘œë‚˜ ì´íƒ¤ë¦­ì²´)
            work_patterns = [
                r'"([^"]+)"',
                r"'([^']+)'",
                r'\*([^*]+)\*',
                r'_([^_]+)_'
            ]
            
            for pattern in work_patterns:
                matches = re.findall(pattern, section_text)
                works.extend(matches)
        
        return works[:10]  # ìµœëŒ€ 10ê°œ
    
    def extract_wikidata_id(self, page) -> Optional[str]:
        """
        Wikidata ID ì¶”ì¶œ
        """
        try:
            # Wikipedia APIë¥¼ í†µí•´ Wikidata ID ê°€ì ¸ì˜¤ê¸°
            api_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{page.title}"
            response = requests.get(api_url)
            if response.status_code == 200:
                data = response.json()
                wikibase_item = data.get('wikibase_item')
                if wikibase_item:
                    return wikibase_item
        except Exception as e:
            logger.warning(f"Wikidata ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return None
    
    def extract_main_image(self, page) -> Optional[str]:
        """
        ë©”ì¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        """
        try:
            # Wikipedia APIë¥¼ í†µí•´ ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            api_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{page.title}"
            response = requests.get(api_url)
            if response.status_code == 200:
                data = response.json()
                thumbnail = data.get('thumbnail', {})
                if thumbnail:
                    return thumbnail.get('source')
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return None
    
    def extract_categories(self, page) -> List[str]:
        """
        Wikipedia ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        """
        try:
            categories = list(page.categories.keys())
            # ì•„í‹°ìŠ¤íŠ¸ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
            art_related = []
            for cat in categories:
                cat_lower = cat.lower()
                if any(keyword in cat_lower for keyword in ['artist', 'painter', 'sculptor', 'art']):
                    art_related.append(cat)
            return art_related[:20]  # ìµœëŒ€ 20ê°œ
        except Exception as e:
            logger.warning(f"ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def extract_references(self, page) -> List[str]:
        """
        ì°¸ê³  ë¬¸í—Œ ì¶”ì¶œ
        """
        try:
            # ê°„ë‹¨í•œ ë§í¬ ì¶”ì¶œ
            links = list(page.links.keys())[:10]  # ì²˜ìŒ 10ê°œ ë§í¬
            return links
        except Exception as e:
            logger.warning(f"ì°¸ê³  ë¬¸í—Œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def search_korean_wikipedia(self, artist_name: str, artist_info: ArtistInfo) -> Optional[Dict]:
        """
        í•œêµ­ì–´ Wikipedia ê²€ìƒ‰
        """
        try:
            # ì˜ë¬¸ëª…ìœ¼ë¡œ í•œêµ­ì–´ í˜ì´ì§€ ê²€ìƒ‰
            ko_page = self.wiki_ko.page(artist_name)
            
            if ko_page.exists():
                return {
                    'name_ko': ko_page.title,
                    'biography_ko': ko_page.text[:1000] if ko_page.text else None
                }
            
            # ë²ˆì—­ëœ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (OpenAI í™œìš©)
            if os.getenv('OPENAI_API_KEY'):
                translated_name = self.translate_artist_name(artist_name)
                if translated_name:
                    ko_page = self.wiki_ko.page(translated_name)
                    if ko_page.exists():
                        return {
                            'name_ko': ko_page.title,
                            'biography_ko': ko_page.text[:1000] if ko_page.text else None
                        }
        
        except Exception as e:
            logger.warning(f"í•œêµ­ì–´ Wikipedia ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return None
    
    def translate_artist_name(self, name: str) -> Optional[str]:
        """
        OpenAIë¥¼ ì‚¬ìš©í•œ ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ ë²ˆì—­
        """
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì˜ˆìˆ ê°€ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ë§Œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": f"ë‹¤ìŒ ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: {name}"
                    }
                ],
                max_tokens=50,
                temperature=0.1
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.warning(f"ì´ë¦„ ë²ˆì—­ ì‹¤íŒ¨: {e}")
            return None
    
    def merge_korean_info(self, artist_info: ArtistInfo, ko_info: Dict) -> ArtistInfo:
        """
        í•œêµ­ì–´ ì •ë³´ ë³‘í•©
        """
        if ko_info.get('name_ko'):
            artist_info.name_ko = ko_info['name_ko']
        if ko_info.get('biography_ko'):
            artist_info.biography_ko = ko_info['biography_ko']
        
        return artist_info
    
    def fetch_wikidata_info(self, wikidata_id: str) -> Optional[Dict]:
        """
        Wikidataì—ì„œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
        """
        if not wikidata_id:
            return None
        
        try:
            query = f"""
            SELECT ?item ?itemLabel ?birthDate ?deathDate ?nationalityLabel ?occupationLabel ?educatedAtLabel WHERE {{
              BIND(wd:{wikidata_id} AS ?item)
              OPTIONAL {{ ?item wdt:P569 ?birthDate. }}
              OPTIONAL {{ ?item wdt:P570 ?deathDate. }}
              OPTIONAL {{ ?item wdt:P27 ?nationality. }}
              OPTIONAL {{ ?item wdt:P106 ?occupation. }}
              OPTIONAL {{ ?item wdt:P69 ?educatedAt. }}
              SERVICE wikibase:label {{ bd:serviceParam wikibase:language "en". }}
            }}
            """
            
            url = "https://query.wikidata.org/sparql"
            response = requests.get(url, params={
                'query': query,
                'format': 'json'
            }, headers={
                'User-Agent': 'SAYU-ArtCollector/1.0'
            })
            
            if response.status_code == 200:
                data = response.json()
                bindings = data.get('results', {}).get('bindings', [])
                if bindings:
                    return bindings[0]
            
        except Exception as e:
            logger.warning(f"Wikidata ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return None
    
    def merge_wikidata_info(self, artist_info: ArtistInfo, wikidata_info: Dict) -> ArtistInfo:
        """
        Wikidata ì •ë³´ ë³‘í•©
        """
        # ë” ì •í™•í•œ ë‚ ì§œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
        if 'birthDate' in wikidata_info and wikidata_info['birthDate']['value']:
            birth_date = wikidata_info['birthDate']['value']
            artist_info.birth_date = birth_date
            if not artist_info.birth_year:
                artist_info.birth_year = int(birth_date[:4])
        
        if 'deathDate' in wikidata_info and wikidata_info['deathDate']['value']:
            death_date = wikidata_info['deathDate']['value']
            artist_info.death_date = death_date
            if not artist_info.death_year:
                artist_info.death_year = int(death_date[:4])
        
        # êµìœ¡ ê¸°ê´€ ì •ë³´
        if 'educatedAtLabel' in wikidata_info:
            if not artist_info.education:
                artist_info.education = []
            artist_info.education.append(wikidata_info['educatedAtLabel']['value'])
        
        return artist_info
    
    def search_variations(self, artist_name: str) -> List[str]:
        """
        ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ ë³€í˜• ê²€ìƒ‰
        """
        try:
            api_url = "https://en.wikipedia.org/api/rest_v1/page/search"
            response = requests.get(api_url, params={
                'q': artist_name,
                'limit': 5
            })
            
            if response.status_code == 200:
                data = response.json()
                pages = data.get('pages', [])
                return [page['title'] for page in pages]
                
        except Exception as e:
            logger.warning(f"ê²€ìƒ‰ ë³€í˜• ì‹¤íŒ¨: {e}")
        
        return []
    
    def save_to_database(self, artist_info: ArtistInfo) -> bool:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì— ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ì €ì¥
        """
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # ì¤‘ë³µ í™•ì¸
            cursor.execute(
                "SELECT id FROM artists WHERE LOWER(name) = LOWER(%s)",
                (artist_info.name,)
            )
            
            existing = cursor.fetchone()
            
            if existing:
                # ì—…ë°ì´íŠ¸
                update_query = """
                UPDATE artists SET
                    name_ko = COALESCE(%s, name_ko),
                    birth_year = COALESCE(%s, birth_year),
                    death_year = COALESCE(%s, death_year),
                    nationality = COALESCE(%s, nationality),
                    nationality_ko = COALESCE(%s, nationality_ko),
                    bio = COALESCE(%s, bio),
                    bio_ko = COALESCE(%s, bio_ko),
                    era = COALESCE(%s, era),
                    images = COALESCE(%s, images),
                    sources = COALESCE(%s, sources),
                    official_links = COALESCE(%s, official_links),
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
                RETURNING id
                """
                
                cursor.execute(update_query, (
                    artist_info.name_ko,
                    artist_info.birth_year,
                    artist_info.death_year,
                    artist_info.nationality,
                    artist_info.nationality_ko,
                    artist_info.biography,
                    artist_info.biography_ko,
                    self.classify_era(artist_info.birth_year, artist_info.death_year),
                    json.dumps({'portrait': artist_info.image_url} if artist_info.image_url else {}),
                    json.dumps({
                        'wikipedia': 'collected',
                        'wikidata': artist_info.wikidata_id
                    }),
                    json.dumps({'wikipedia': artist_info.wikipedia_url} if artist_info.wikipedia_url else {}),
                    existing['id']
                ))
                
                logger.info(f"âœ… ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ì—…ë°ì´íŠ¸: {artist_info.name}")
                
            else:
                # ìƒˆë¡œ ì‚½ì…
                insert_query = """
                INSERT INTO artists (
                    name, name_ko, birth_year, death_year, nationality, nationality_ko,
                    bio, bio_ko, copyright_status, era, images, sources, official_links,
                    is_featured
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
                """
                
                cursor.execute(insert_query, (
                    artist_info.name,
                    artist_info.name_ko,
                    artist_info.birth_year,
                    artist_info.death_year,
                    artist_info.nationality,
                    artist_info.nationality_ko,
                    artist_info.biography,
                    artist_info.biography_ko,
                    self.determine_copyright_status(artist_info),
                    self.classify_era(artist_info.birth_year, artist_info.death_year),
                    json.dumps({'portrait': artist_info.image_url} if artist_info.image_url else {}),
                    json.dumps({
                        'wikipedia': 'collected',
                        'wikidata': artist_info.wikidata_id
                    }),
                    json.dumps({'wikipedia': artist_info.wikipedia_url} if artist_info.wikipedia_url else {}),
                    len(artist_info.notable_works or []) > 5  # ìœ ëª… ì‘í’ˆì´ ë§ìœ¼ë©´ featured
                ))
                
                logger.info(f"âœ… ìƒˆ ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ì €ì¥: {artist_info.name}")
            
            conn.commit()
            cursor.close()
            conn.close()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def classify_era(self, birth_year: int, death_year: int) -> str:
        """ì‹œëŒ€ ë¶„ë¥˜"""
        if not birth_year:
            return 'Contemporary'
        
        active_year = death_year or datetime.now().year
        
        if active_year < 1400:
            return 'Medieval'
        elif active_year < 1600:
            return 'Renaissance'
        elif active_year < 1750:
            return 'Baroque'
        elif active_year < 1850:
            return 'Neoclassicism'
        elif active_year < 1900:
            return 'Impressionism'
        elif active_year < 1945:
            return 'Modern'
        elif active_year < 1980:
            return 'Postmodern'
        else:
            return 'Contemporary'
    
    def determine_copyright_status(self, artist_info: ArtistInfo) -> str:
        """ì €ì‘ê¶Œ ìƒíƒœ íŒë‹¨"""
        current_year = datetime.now().year
        
        if artist_info.death_year:
            years_since_death = current_year - artist_info.death_year
            if years_since_death >= 70:
                return 'public_domain'
            elif years_since_death >= 50:
                return 'transitional'
            else:
                return 'licensed'
        elif artist_info.birth_year:
            age = current_year - artist_info.birth_year
            if age > 150:
                return 'public_domain'
            else:
                return 'contemporary'
        
        return 'unknown'
    
    def process_batch(self, artist_names: List[str]) -> Dict[str, Any]:
        """
        ë°°ì¹˜ë¡œ ì—¬ëŸ¬ ì•„í‹°ìŠ¤íŠ¸ ì²˜ë¦¬
        """
        results = {
            'successful': [],
            'failed': [],
            'total': len(artist_names)
        }
        
        logger.info(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(artist_names)}ëª…ì˜ ì•„í‹°ìŠ¤íŠ¸")
        
        for i, name in enumerate(artist_names, 1):
            logger.info(f"ğŸ¨ ì²˜ë¦¬ ì¤‘ [{i}/{len(artist_names)}]: {name}")
            
            try:
                artist_info = self.search_artist(name)
                if artist_info:
                    if self.save_to_database(artist_info):
                        results['successful'].append({
                            'name': name,
                            'info': artist_info
                        })
                    else:
                        results['failed'].append({
                            'name': name,
                            'error': 'Database save failed'
                        })
                else:
                    results['failed'].append({
                        'name': name,
                        'error': 'Artist not found or not valid'
                    })
                    
            except Exception as e:
                results['failed'].append({
                    'name': name,
                    'error': str(e)
                })
            
            # API ìœ¨í•œ ì œí•œ ê³ ë ¤í•œ ì§€ì—°
            import time
            time.sleep(1)
        
        logger.info(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {len(results['successful'])}, ì‹¤íŒ¨ {len(results['failed'])}")
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='SAYU Wikipedia ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘ê¸°')
    parser.add_argument('--artist', '-a', help='ë‹¨ì¼ ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„')
    parser.add_argument('--batch', '-b', help='ì•„í‹°ìŠ¤íŠ¸ ëª©ë¡ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', '-o', help='ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON)', default='artist_results.json')
    
    args = parser.parse_args()
    
    collector = WikipediaArtistCollector()
    
    if args.artist:
        # ë‹¨ì¼ ì•„í‹°ìŠ¤íŠ¸ ì²˜ë¦¬
        artist_info = collector.search_artist(args.artist)
        if artist_info:
            if collector.save_to_database(artist_info):
                print(f"âœ… '{args.artist}' ì •ë³´ ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ")
            else:
                print(f"âŒ '{args.artist}' DB ì €ì¥ ì‹¤íŒ¨")
        else:
            print(f"âŒ '{args.artist}' ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    elif args.batch:
        # ë°°ì¹˜ ì²˜ë¦¬
        try:
            with open(args.batch, 'r', encoding='utf-8') as f:
                artist_names = [line.strip() for line in f if line.strip()]
            
            results = collector.process_batch(artist_names)
            
            # ê²°ê³¼ ì €ì¥
            with open(args.output, 'w', encoding='utf-8') as f:
                # JSON serializable í˜•íƒœë¡œ ë³€í™˜
                serializable_results = {
                    'successful': [
                        {
                            'name': item['name'],
                            'info': {
                                'name': item['info'].name,
                                'birth_year': item['info'].birth_year,
                                'death_year': item['info'].death_year,
                                'nationality': item['info'].nationality,
                                'biography': item['info'].biography[:200] if item['info'].biography else None
                            }
                        } for item in results['successful']
                    ],
                    'failed': results['failed'],
                    'total': results['total'],
                    'success_rate': f"{len(results['successful'])/results['total']*100:.1f}%"
                }
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š ê²°ê³¼ê°€ {args.output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
            print(f"ì„±ê³µ: {len(results['successful'])}, ì‹¤íŒ¨: {len(results['failed'])}")
            
        except FileNotFoundError:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.batch}")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()